{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edf556e-51be-4347-9d5e-27e56e6a6e4a",
   "metadata": {},
   "source": [
    "# Funny birds to Time Series"
   ]
  },
  {
   "cell_type": "code",
   "id": "80b4c445-e5a0-4814-a11e-7b46a260b5ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "import enum\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d0df0dd0b5104",
   "metadata": {},
   "source": [
    "The enumerate `Center` indicates which center to use to obtain the time series:\n",
    "\n",
    "- `Center.IMG`. Center of the image.\n",
    "- `Center.CONTOUR`. The center of each contour. The resulting time series will vary a lot.\n",
    "- `Center.FIRST_CONTOUR`."
   ]
  },
  {
   "cell_type": "code",
   "id": "97e243f9-8397-4080-b9f4-eb61ba55f4fe",
   "metadata": {},
   "source": [
    "\n",
    "class Center(enum.Enum):\n",
    "    IMG = 0\n",
    "    CONTOUR = 1\n",
    "    FIRST_CONTOUR = 2\n",
    "\n",
    "    def __str__(self):\n",
    "        claus = {0: \"I\", 1: \"C\", 2: \"CO\"}\n",
    "\n",
    "        return claus[self.value]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e3571dc42b55a9",
   "metadata": {},
   "source": [
    "TEST = True\n",
    "\n",
    "BODY_COLOR_PARTS = 170\n",
    "BACKGROUND_COLOR_PARTS = 255\n",
    "CENTER = Center.FIRST_CONTOUR\n",
    "\n",
    "BACKGROUND_COLOR_IMG = (85, 85, 153)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91b0e669-db3d-422b-a1a5-e374b15315e3",
   "metadata": {},
   "source": [
    "## Mask creation"
   ]
  },
  {
   "cell_type": "code",
   "id": "5332793a-1a52-4167-b80e-57eeb46628fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "def are_all_similar(a, b, c, tolerance=5):\n",
    "    \"\"\" Determine if all three arrays are similar within a given tolerance.\n",
    "\n",
    "    Args:\n",
    "        a: Numpy array of values.\n",
    "        b: Numpy array of values.\n",
    "        c: Numpy array of values.\n",
    "        tolerance: Tolerance level for similarity.\n",
    "\n",
    "    Returns:\n",
    "        Boolean numpy array indicating if all three arrays are similar within the tolerance.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        np.logical_and(abs(a - b) <= tolerance,\n",
    "                       np.logical_and(abs(a - c) <= tolerance, abs(b - c) <= tolerance))\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mask(parts, tolerance=5):\n",
    "    \"\"\" Returns a binary mask from a parts image.\n",
    "\n",
    "    A parts image indicated each pixel corresponding to a different part. The background are always \n",
    "\n",
    "    Args:\n",
    "        parts:  Image array of shape (H, W, 3), where each pixel's RGB value indicates the part label.\n",
    "        tolerance: Tolerance level for color similarity.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array of shape (H, W) representing the binary mask, where 1 indicates foreground and 0 indicates background.\n",
    "    \"\"\"\n",
    "    parts_unic = parts.reshape(-1, parts.shape[2])\n",
    "    parts_unic = np.unique(parts_unic, axis=0)\n",
    "    parts_unic = parts_unic.astype(np.float64)\n",
    "    diff = are_all_similar(parts_unic[:, 0], parts_unic[:, 1], parts_unic[:, 2], tolerance)\n",
    "\n",
    "    values = parts_unic[diff]\n",
    "    mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "    for val in values:\n",
    "        if (val[0] == BODY_COLOR_PARTS) or (val[0] == BACKGROUND_COLOR_PARTS):\n",
    "            continue\n",
    "        # Binary mask of the object, adding each part\n",
    "        mask = mask + np.logical_and.reduce(\n",
    "            (parts[:, :, 0] == val[0], parts[:, :, 1] == val[1], parts[:, :, 2] == val[2]))\n",
    "\n",
    "    return 1 - mask\n",
    "\n",
    "\n",
    "def get_time_series(mask, center=None, return_points=False):\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cnts = sorted(cnts, key=lambda x: x.size, reverse=True)\n",
    "\n",
    "    multiple_cnts = (len(cnts) > 1) and (cnts[1].size > 500)\n",
    "\n",
    "    cnt = cnts[0]\n",
    "\n",
    "    if center is None:\n",
    "        M = cv2.moments(cnt)\n",
    "        center = int(M[\"m01\"] / M[\"m00\"]), int(M[\"m10\"] / M[\"m00\"])\n",
    "\n",
    "    time_series = []\n",
    "\n",
    "    for point in cnt:\n",
    "        point = point[0]\n",
    "        time_series.append(\n",
    "            float(np.sqrt((point[0] - center[0]) ** 2 + (point[1] - center[1]) ** 2)))\n",
    "\n",
    "    if return_points:\n",
    "        return time_series, center, multiple_cnts, cnt\n",
    "    else:\n",
    "        return time_series, center, multiple_cnts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "adeea7bd-bd78-4323-8e65-3c80894fe404",
   "metadata": {},
   "source": [
    "if TEST:\n",
    "    part_map_paths = \"./data/funny_birds/v2/test_part_map\"\n",
    "    inter_map_paths = \"./data/funny_birds/v2/test_interventions\"\n",
    "else:\n",
    "    part_map_paths = \"./data/funny_birds/v2/train_part_map\"\n",
    "    inter_map_paths = None\n",
    "\n",
    "IMG_PATH = f\"./{part_map_paths}/**/*.png\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e1f2255-81a8-4cfa-a3d6-d17bd04cf4a7",
   "metadata": {},
   "source": [
    "images_paths = sorted(glob.glob(IMG_PATH))\n",
    "\n",
    "classes = set()\n",
    "for p in images_paths:\n",
    "    classe = int(p.split(os.path.sep)[-2])\n",
    "\n",
    "    if classe not in classes:\n",
    "        classes.add(classe)\n",
    "\n",
    "cls_dict = {}\n",
    "for i, classe in enumerate(classes):\n",
    "    cls_dict[classe] = i"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "110fb546-4029-49f7-9c66-17e9b22d7d15",
   "metadata": {
    "tags": []
   },
   "source": [
    "if TEST:\n",
    "    folder_name = \"test\"\n",
    "else:\n",
    "    folder_name = \"train\"\n",
    "\n",
    "for i, img_path in enumerate(tqdm(images_paths)):\n",
    "    path_parts = img_path.split(os.path.sep)\n",
    "    bird_class = path_parts[-2]\n",
    "    bird_class_translated = cls_dict[int(bird_class)]\n",
    "\n",
    "    file_img_name = path_parts[-1]\n",
    "    img_name = file_img_name.split(\".\")[0]\n",
    "\n",
    "    img_parts = Image.open(img_path)\n",
    "    img_parts = np.array(img_parts)[:, :, :-1]\n",
    "    mask = get_mask(img_parts, 40)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n",
    "    mask[mask != 0] = 1\n",
    "\n",
    "    if mask.max() == 0:\n",
    "        print(f\"Image {img_path} empty\")\n",
    "        continue\n",
    "\n",
    "    # Path of the mask\n",
    "    out_path = os.path.join(\"output\", f\"{folder_name}_{CENTER}\",\n",
    "                            str(bird_class_translated).zfill(3), img_name)\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    cv2.imwrite(f\"./{out_path}/image.png\", mask * 255)\n",
    "\n",
    "    # To Time series\n",
    "    center_img = mask.shape[0] // 2, mask.shape[1] // 2\n",
    "\n",
    "    center = None\n",
    "\n",
    "    time_series, center_cnt, multiple_cnts, cnt = get_time_series(mask.astype(np.uint8), return_points=True)\n",
    "\n",
    "    if multiple_cnts:\n",
    "        print(f\"Image {str(i).zfill(5)} multiple cnts\")\n",
    "        continue\n",
    "\n",
    "    if CENTER is Center.IMG:\n",
    "        center = center_img\n",
    "    elif CENTER is Center.CONTOUR:  # Center of the first contour\n",
    "        center = center_cnt\n",
    "\n",
    "    with open(f\"./{out_path}/time_series.json\", \"w\") as final:\n",
    "        json.dump(time_series, final)\n",
    "\n",
    "    # Saving interventions\n",
    "    if inter_map_paths is not None:\n",
    "        for interv_paths in tqdm(\n",
    "                sorted(glob.glob(f\"./{inter_map_paths}/{bird_class}/{img_name}/*.png\")),\n",
    "                leave=False):\n",
    "            name_intervent = interv_paths.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\n",
    "            intervention = np.array(Image.open(interv_paths))[:, :, :-1]\n",
    "\n",
    "            logical_mask = 1 - np.logical_and.reduce(\n",
    "                (intervention[:, :, 0] == BACKGROUND_COLOR_IMG[0],\n",
    "                 intervention[:, :, 1] == BACKGROUND_COLOR_IMG[1],\n",
    "                 intervention[:, :, 2] == BACKGROUND_COLOR_IMG[2])\n",
    "            )\n",
    "            logical_mask = mask * logical_mask\n",
    "\n",
    "            time_series, _, _ = get_time_series(logical_mask.astype(np.uint8), center)\n",
    "\n",
    "            with open(f\"./{out_path}/{name_intervent}.json\", \"w\") as final:\n",
    "                json.dump(time_series, final)\n",
    "\n",
    "            cv2.imwrite(f\"./{out_path}/{name_intervent}.png\", logical_mask * 255)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
