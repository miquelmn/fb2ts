{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d9e10-0177-4c33-ac0a-e5206c979018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from IPython import display\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models.vision_transformer import VisionTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0783f1c-a8b0-48d5-8e3f-d327093f657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "OHE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb122879-57cd-43dc-932d-8791f82cefed",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a77bb8-66cd-4fc6-9621-b3c4948f8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"General pytorch dataset.\n",
    "\n",
    "    The data should be build with the following structure.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_paths: List[str],\n",
    "        read_img_fn: callable,\n",
    "        transform=None,\n",
    "        do_ohe: bool = False\n",
    "    ):\n",
    "        self.__read_img_fn = read_img_fn\n",
    "        \n",
    "        self.__img_paths = img_paths\n",
    "        self.__transform = transform\n",
    "        self.__do_ohe = do_ohe\n",
    "\n",
    "        self.n_classes = 0\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[np.array, torch.Tensor]:\n",
    "        img_path = self.__img_paths[index]\n",
    "        label = int(img_path.split(os.path.sep)[-3])\n",
    "        \n",
    "\n",
    "        self.n_classes = max(self.n_classes, label)\n",
    "        \n",
    "        image = self.__read_img_fn(img_path)\n",
    "        index = index % len(self.__img_paths)\n",
    "\n",
    "        if self.__transform is not None:\n",
    "            image = self.__transform(image)\n",
    "\n",
    "        if self.__do_ohe:\n",
    "            label_ohe = np.zeros((46))\n",
    "            label_ohe[label] = 1\n",
    "            label = label_ohe\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60880f4-b945-425e-a043-74db8fb63ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob.glob(\"./output/train_CO/**/**/image.png\")\n",
    "test_path = glob.glob(\"./output/test_CO/**/**/image.png\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), v2.ToDtype(torch.float)])\n",
    "\n",
    "train_ds = ImageDataset(train_path, Image.open, transform, do_ohe=OHE)\n",
    "train_loader = DataLoader(train_ds, batch_size=100, shuffle=True)\n",
    "\n",
    "test_ds = ImageDataset(test_path, Image.open, transform, do_ohe=OHE)\n",
    "test_loader = DataLoader(test_ds, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197de3a7-3efe-4f96-a643-6a373ae1ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_progress(history, phases):\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    for phase in phases:\n",
    "        pl.subplot(1, 2, 1)\n",
    "        pl.title(f'Best Acc: {max(history[phase][\"acc\"])}')\n",
    "\n",
    "        pl.plot(history[phase]['acc'], label=phase.capitalize())\n",
    "        pl.legend()\n",
    "\n",
    "    for phase in phases:\n",
    "        pl.subplot(1, 2, 2)\n",
    "        pl.title(f'Best loss: {min(history[phase][\"loss\"])}')\n",
    "        pl.plot(history[phase]['loss'], label=phase.capitalize())\n",
    "\n",
    "        pl.legend()\n",
    "    display.clear_output(wait=True) \n",
    "    display.display(pl.gcf())\n",
    "    plt.close() \n",
    "    \n",
    "def train_model(\n",
    "    model, \n",
    "    dataloaders, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs=25, \n",
    "    is_inception=False, \n",
    "    do_validation=True, \n",
    "    regression=False,\n",
    "    plot_acc=False,\n",
    "):\n",
    "    since = time.time()\n",
    "\n",
    "    wandb.init(project=\"taixi\", config={\n",
    "        \"epochs\": num_epochs,\n",
    "        \"lr\": LR,\n",
    "        \"first_n_layers\": FIRST_N_LAYERS,\n",
    "        \"dropout\": DROPOUT,\n",
    "    })\n",
    "    \n",
    "    history = {}\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_acc_std = 0.0\n",
    "    best_loss = 0.0\n",
    "    best_loss_std = 0.0\n",
    "    \n",
    "    phases = ['train']\n",
    "    \n",
    "    if do_validation:\n",
    "        phases.append('val')\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            # Each epoch has a training and validation phase\n",
    "    \n",
    "            res = dict()\n",
    "            for phase in phases:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "    \n",
    "                running_loss = []\n",
    "                running_acc = []\n",
    "    \n",
    "                pbar = tqdm(dataloaders[phase], desc='Time, he\\'s waiting in the wings')\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in pbar:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "    \n",
    "                    inputs = inputs.type(torch.float32)\n",
    "    \n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "    \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # Get model outputs and calculate loss\n",
    "                        # Special case for inception because in training it has an auxiliary output. In train\n",
    "                        #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                        #   but in testing we only consider the final output.\n",
    "                        outputs = model(inputs)                      \n",
    "                        loss = criterion(outputs, labels)\n",
    "    \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "    \n",
    "                    # statistics\n",
    "                    running_loss.append((loss.item() * inputs.size(0)) / len(outputs))\n",
    "                    preds = torch.argmax(outputs, 1).detach().cpu()\n",
    "    \n",
    "                    # labels = torch.argmax(labels, 1).reshape(-1).detach().cpu()\n",
    "                    labels = labels.reshape(-1).detach().cpu()\n",
    "                    \n",
    "                    # aux = ((preds > 0.5).double() == labels)\n",
    "                    # acc = (torch.sum(aux).double().cpu().detach().numpy() / len(outputs))\n",
    "                    acc = accuracy_score(labels, preds)\n",
    "                    running_acc.append(acc)\n",
    "                        \n",
    "                    pbar.set_description('Epoch {}/{} - {} - ACC: {:.4f} LOSS: {:.4f}'.format(epoch, num_epochs - 1, phase.capitalize(), np.mean(running_acc), np.mean(running_loss)))\n",
    "                \n",
    "                epoch_loss = np.mean(running_loss)\n",
    "                epoch_acc = np.mean(running_acc)\n",
    "    \n",
    "                res[f\"{phase}_loss\"] = epoch_loss \n",
    "                res[f\"{phase}_accuracy\"] = epoch_acc\n",
    "    \n",
    "                # deep copy the model\n",
    "                if (phase == 'val' or not 'val' in phases) and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_loss = epoch_loss\n",
    "    \n",
    "                    best_loss_std = np.std(running_loss)\n",
    "                    best_acc_std = np.std(running_acc)\n",
    "    \n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "                if phase not in history:\n",
    "                    history[phase] = {\"acc\": [], \"loss\": []}\n",
    "    \n",
    "                history[phase][\"acc\"].append(epoch_acc)\n",
    "                history[phase][\"loss\"].append(epoch_loss)\n",
    "    \n",
    "            wandb.log(res)\n",
    "            if plot_acc:\n",
    "                _show_progress(history, phases)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val Acc: [{:4f}-{:4f}]'.format(best_acc - best_acc_std/2, best_acc + best_acc_std/2))\n",
    "        \n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154a6c4-fcca-4ceb-9813-17798c3d96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.00001\n",
    "FIRST_N_LAYERS = 1\n",
    "DROPOUT = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d30c1-401f-468c-a029-44c89d91be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet50(pretrained=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for i, param in enumerate(net.parameters()):\n",
    "    if i == FIRST_N_LAYERS:\n",
    "        break\n",
    "    \n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "num_ftrs = net.fc.in_features\n",
    "    \n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                           bias=False)\n",
    "\n",
    "\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=DROPOUT),\n",
    "    nn.Linear(128, 47),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dbc574-bfa8-4ad1-bf13-a07c53944307",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337abef-2952-4060-a81f-ee54e01555cd",
   "metadata": {},
   "source": [
    "## Entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2023f70-e3e5-4247-935b-45a78f96b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "net, history = train_model(\n",
    "    net, \n",
    "    {\"train\": train_loader, \"val\": test_loader}, \n",
    "    criterion, \n",
    "    optimizer,\n",
    "    num_epochs=100, \n",
    "    do_validation=True,\n",
    "    plot_acc=True,\n",
    "    regression=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbb092-89c6-42f1-9ad6-c65f7089044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), \"res_9.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a447417-8869-45e1-b952-1e47539fb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history['val']['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b3db4-410f-4956-af20-473d32f31847",
   "metadata": {},
   "source": [
    "# An√†lisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75385ac-83ee-4972-920c-482a99918cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load(\"res.pt\", weights_only=True))\n",
    "net = net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a6934-7288-4b59-808d-6b464cf4828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = np.zeros(5)\n",
    "aux[2] = -5\n",
    "\n",
    "np.argsort(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b89153-b1f6-4843-8765-ed031fcbc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "ground_truth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be9cd2-cc05-49f5-9f37-fadc1e38f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in tqdm(test_loader):\n",
    "    res = net(inputs.to(device)).detach()\n",
    "    \n",
    "    results = results + torch.argmax(res, axis=-1).detach().cpu().tolist()\n",
    "    ground_truth = ground_truth + labels.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ea920-4049-43fc-9e45-b0662baa0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ground_truth, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94d344-0f6a-4c4f-9f21-de61fa4b1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ground_truth, results)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(include_values=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d854c7-14c9-46df-a9b6-d465dc9744c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(cm[7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
